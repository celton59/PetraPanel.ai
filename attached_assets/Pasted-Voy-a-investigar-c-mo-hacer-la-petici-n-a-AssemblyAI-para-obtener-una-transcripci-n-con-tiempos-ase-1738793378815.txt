Voy a investigar cómo hacer la petición a AssemblyAI para obtener una transcripción con tiempos, asegurándome de que tu implementación en JavaScript con Express capture correctamente los timestamps junto con el texto transcrito. Te informaré en cuanto tenga la información lista.

Research completed in 2m· 16 fuentes
Transcribir audio con AssemblyAI incluyendo timestamps
Documentación de AssemblyAI sobre timestamps
La documentación oficial de AssemblyAI indica que el resultado de una transcripción incluye, además del texto completo, un arreglo detallado de palabras con sus respectivos timestamps (tiempos de inicio y fin) y otros datos como el nivel de confianza​
ASSEMBLYAI.COM
. En otras palabras, cada palabra reconocida viene acompañada de marcas de tiempo en milisegundos indicando cuándo inicia y termina en el audio. Por ejemplo, la respuesta JSON de AssemblyAI contiene una sección words donde vemos entradas como:

text
Copiar
Word(text='Smoke', start=250, end=650, confidence=0.73033)
En este ejemplo (tomado de la documentación), la palabra “Smoke” tiene start: 250 y end: 650, lo que indica que fue pronunciada aproximadamente entre los 0,25 y 0,65 segundos del audio​
ASSEMBLYAI.COM
. De esta forma, se pueden obtener timestamps palabra por palabra a partir de la respuesta de la API.

Opciones necesarias en la solicitud para obtener tiempos
Para recibir los timestamps no es necesario activar un parámetro especial – la API de AssemblyAI los incluye por defecto en el campo words de la respuesta​
ASSEMBLYAI.COM
. Sin embargo, debemos asegurarnos de armar correctamente la petición HTTP de transcripción. Los puntos clave son:

Endpoint correcto: Usar la URL de la API v2 de AssemblyAI (por ejemplo, https://api.assemblyai.com/v2/transcript).
Headers de autenticación y contenido: Incluir el encabezado authorization con tu API key de AssemblyAI, y Content-Type: application/json en la solicitud.
Cuerpo JSON adecuado: Enviar un JSON con al menos el parámetro audio_url apuntando al archivo de audio (o usar un upload_url si primero subiste el audio a AssemblyAI). Opcionalmente, puedes incluir otros ajustes como punctuate o format_text (por defecto están en true para agregar puntuación y formato al texto).
AssemblyAI procesará la solicitud asíncronamente. Al hacer la petición de transcripción recibirás un ID de transcripción; con ese ID deberás consultar el estado periódicamente hasta que el campo status sea "completed". Finalmente, al obtener el resultado, encontrarás el texto completo en text y el arreglo de palabras con sus timestamps en words. No olvides manejar también el caso status: "error" (por ejemplo, mostrando el mensaje de error si la transcripción falla).

Precisión de los timestamps y parámetros adicionales
Los timestamps proporcionados por AssemblyAI tienen una precisión de alrededor de ±0,4 segundos (400 ms)​
ASSEMBLYAI.COM
. Esto significa que la marca de tiempo de inicio y fin de cada palabra puede variar ligeramente (hasta unos cientos de milisegundos) respecto al audio real. No existe un parámetro configurable específico para mejorar directamente esta precisión, ya que está limitada por el propio modelo de reconocimiento de voz​
ASSEMBLYAI.COM
.

No obstante, asegurar la mejor calidad de transcripción sí ayudará a tener timestamps más confiables. Para ello:

Utiliza el modelo más preciso de AssemblyAI (el modelo "Best", que es el predeterminado para transcripciones asíncronas​
ASSEMBLYAI.COM
). Este modelo ofrece la mayor exactitud, lo que indirectamente contribuye a timestamps más consistentes.
Proporciona audio de buena calidad (claridad en las voces, poco ruido de fondo) para que el reconocimiento sea óptimo.
Si tienes vocabulario inusual o nombres propios, considera usar Custom Vocabulary (vocabulario personalizado) para mejorar el reconocimiento de esas palabras​
ASSEMBLYAI.COM
. Aunque esto no ajusta directamente el tiempo, sí puede evitar errores de transcripción que afectarían la alineación temporal de las palabras clave.
En resumen, los timestamps palabra-por-palabra ya vienen incluidos y son razonablemente precisos, pero siempre habrá un pequeño margen de variación. En la mayoría de los casos no necesitas parámetros extra para obtenerlos o afinarlos, más allá de utilizar las configuraciones estándar que aseguren la mejor calidad de transcripción.

Ejemplo de código: función transcribeAudio con timestamps
A continuación se muestra un ejemplo de cómo modificar la función transcribeAudio (en un entorno Node.js con Express) para solicitar la transcripción a AssemblyAI incluyendo los timestamps. En este ejemplo se usa fetch para realizar las peticiones HTTP (suponiendo que has importado node-fetch u otro fetch polyfill para Node):

javascript
Copiar
const fetch = require('node-fetch'); // Asegúrate de tener node-fetch u otro método de fetch disponible
const API_KEY = 'TU_API_KEY_DE_ASSEMBLYAI';

async function transcribeAudio(audioUrl) {
  // 1. Hacer POST a /v2/transcript para iniciar la transcripción
  const response = await fetch('https://api.assemblyai.com/v2/transcript', {
    method: 'POST',
    headers: {
      'authorization': API_KEY,           // Tu clave de API de AssemblyAI
      'content-type': 'application/json'  // Enviamos JSON
    },
    body: JSON.stringify({
      audio_url: audioUrl,
      // Opcional: parámetros adicionales
      punctuate: true,       // agrega puntuación automática (opción por defecto)
      format_text: true      // da formato al texto (mayúsculas, números) por defecto
      // No se requiere ningún parámetro especial para obtener timestamps: 
      // la respuesta incluirá "words" automáticamente.
    })
  });
  
  const data = await response.json();
  const transcriptId = data.id;
  
  // 2. Consultar periódicamente hasta que la transcripción esté lista
  let transcriptData;
  do {
    await new Promise(res => setTimeout(res, 2000));  // esperar 2 segundos antes de cada consulta
    const resultRes = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
      headers: { 'authorization': API_KEY }
    });
    transcriptData = await resultRes.json();
  } while (transcriptData.status !== 'completed' && transcriptData.status !== 'error');
  
  if (transcriptData.status === 'error') {
    throw new Error(`Error en transcripción: ${transcriptData.error}`);
  }
  
  // 3. Retornar el resultado, incluyendo texto y palabras con timestamps
  return {
    text: transcriptData.text,       // Texto transcrito completo
    words: transcriptData.words      // Array de palabras con timestamps y confianza
  };
}
Cómo funciona este código: Primero envía el audio a la API para que sea transcrito. Una vez enviada la solicitud, obtiene un transcriptId y luego hace polling (consulta repetida) al endpoint de resultado hasta que la transcripción esté lista (status: "completed"). Al finalizar, retornamos un objeto con el texto completo (text) y la lista de palabras con sus timestamps (words). Cada elemento de words tendrá la forma { text: "palabra", start: <ms_inicio>, end: <ms_fin>, confidence: <confianza> }, siguiendo el formato descrito en la documentación​
ASSEMBLYAI.COM
.

Con esta implementación, la respuesta de tu función transcribeAudio ya incluirá los timestamps solicitados, y podrás usarlos en tu aplicación (por ejemplo, para mostrar subtítulos sincronizados o resaltar palabras mientras se reproduce el audio).

Referencias: La documentación de AssemblyAI sobre transcripciones detalla la inclusión de timestamps por palabra​
ASSEMBLYAI.COM
 y señala que su precisión es del orden de ~0.4s​
ASSEMBLYAI.COM
. Asegúrate de revisar la API Reference de AssemblyAI para más detalles sobre campos opcionales y buenas prácticas. ¡Con esto podrás transcribir audio con timestamps de manera exitosa en tu proyecto Node/Express!





